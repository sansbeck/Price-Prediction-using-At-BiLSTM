# -*- coding: utf-8 -*-
"""AT_BiLSTM[1].ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11p9rn_wFn8W9dRwj8Zb7Zsvi91JACDji
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import Dropout
from keras.layers import Activation
from keras.models import load_model

df = pd.read_csv('/content/Gold Price.csv')
df.head(5)

df=df.drop(columns=['Date','Open','High','Volume','Low','Chg%'])
df

def lagrange_interpolation(x, y, x_interp):

    def lagrange_basis(j):
        p = np.poly1d([1])
        for m in range(len(x)):
            if m != j:
                p *= np.poly1d([1, -x[m]]) / (x[j] - x[m])
        return p


    result = np.zeros_like(x_interp, dtype=float)
    for j in range(len(x)):
        result += y[j] * lagrange_basis(j)(x_interp)

    return result

def rate_of_return(prices):
    return prices.pct_change()

def price_var(prices, window_size):
    return prices.rolling(window=window_size).var()

df = df.rename(columns={'Price':'Adj Close'})

def moving_average(prices, window_size):
    return prices.rolling(window=window_size).mean()

def psychological_index(returns):
    positive_returns = returns[returns > 0].count()
    total_returns = len(returns)
    return positive_returns / total_returns

def Boll_index(prices, window_size):
    rolling_mean = prices.rolling(window=window_size).mean()
    rolling_std = prices.rolling(window=window_size).std()
    upper_band = rolling_mean + 2 * rolling_std
    middle_band = rolling_mean
    lower_band = rolling_mean - 2 * rolling_std
    return upper_band, middle_band, lower_band

def calculate_rsi(prices, window_size):
    diff = prices.diff()
    gains = diff.where(diff > 0, 0)
    losses = -diff.where(diff < 0, 0)
    avg_gains = gains.rolling(window=window_size, min_periods=1).mean()
    avg_losses = losses.rolling(window=window_size, min_periods=1).mean()
    rs = avg_gains / avg_losses
    rsi = 100 - (100 / (1 + rs))

    return rsi

def xy(data,steps=24):
  x_train = []
  y_train = []

  for i in range(steps, data.shape[0]-steps):
      x_train.append(data.iloc[i-steps:i, :])
      y_train.append(data.iloc[i, :])

  x_train, y_train = np.array(x_train), np.array(y_train)
  return x_train,y_train

df

xt,yt= xy(df[['Adj Close']],20)
# df['Train adj close']=xt
# df['Eng Adj close']=yt
xt

con=pd.DataFrame(xt.reshape(2187,20))

con

ma=moving_average(df['Adj Close'],10)
ma2=moving_average(df['Adj Close'],30)
ror=rate_of_return(df['Adj Close'])
var = price_var(df['Adj Close'], 10)
var2= price_var(df['Adj Close'], 20)
upper,middle,lower = Boll_index(df['Adj Close'], 10)

rsi=calculate_rsi(df['Adj Close'],14)

psycho = psychological_index(ror)

df['Moving Average(10)']=ma
df

df['Moving Average(30)']=ma2
df['Rate of Return']=ror
df['Price Variance(10)']=var
df['Price Variance(20)']=var2
df['Boll Upper']=upper
df['Boll Middle']=middle
df['Boll Lower']=lower
df.head(25)

df['RSI']=rsi

df.shape

data=df[20:]

data

data.tail(20)

data = data[:-20]

data

data.reset_index(drop=True, inplace=True)
data

con.reset_index(drop=True,inplace=True)
con

df=pd.concat([data,con],axis=1)
df

df.head(5)

def remove_rows_with_nan(df):

    while df.isnull().any(axis=1).any():
        rows_with_nan = df[df.isnull().any(axis=1)]
        df = df.dropna()
        if not df.isnull().any(axis=1).any():
            break

    return df

df=remove_rows_with_nan(df)

df

df.reset_index(drop=True, inplace=True)

df

pip install arch

from arch import arch_model
returns = df['Rate of Return']

model = arch_model(returns, vol='Garch', p=1, q=1)
result = model.fit()

stochastic_disturbance = result.resid
conditional_variance = result.conditional_volatility

conditional_variance

stochastic_disturbance

df['Stochastic Disturbance'] = stochastic_disturbance
df['Conditional Variance'] = conditional_variance

df

n_train_rows = int(df.shape[0]*.9)-1
train = df.iloc[:n_train_rows, :]
test = df.iloc[n_train_rows:, :]
print(train.shape)
print(test.shape)

train

X_train= train.drop(columns='Adj Close')
y_train= train['Adj Close'].copy()
X_test= test.drop(columns='Adj Close')
y_test= test['Adj Close'].copy()

X_train

# print(X_train.head(10))
print(y_train.head(10))

X_train.shape

X_train

# sc = MinMaxScaler(feature_range = (0, 1))
# X_training_set_scaled = sc.fit_transform(X_train.values)
# # y_training_set_scaled = sc.fit_transform(y_train.values)
# X_test_set_scaled = sc.fit_transform(X_test.values)
sc_X = MinMaxScaler(feature_range=(0, 1))
sc_y = MinMaxScaler(feature_range=(0, 1))

X_train_scaled = sc_X.fit_transform(X_train.values)
X_test_scaled = sc_X.transform(X_test.values)
y_train_scaled = sc_y.fit_transform(y_train.values.reshape(-1, 1))
y_test_scaled = sc_y.transform(y_test.values.reshape(-1, 1))

# Reshape input to be 3D for LSTM [samples, timesteps, features]
X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))
X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))

X_train_scaled

from keras.layers import Input,Dense, Dropout, Embedding, LSTM, Bidirectional, Concatenate, Attention
from keras.models import Model
from keras.datasets import imdb

from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout, Bidirectional, Layer,Concatenate,Flatten,Attention,Input
from keras.callbacks import EarlyStopping
from keras.optimizers import RMSprop
from keras.models import Model
import tensorflow as tf

input_layer = Input(shape=(X_train_scaled.shape[1], 1))
blstm_layer = Bidirectional(LSTM(units = 69,activation='relu',return_sequences=True))(input_layer)
lstm_layer2 = Bidirectional(LSTM(units = 30,return_sequences=True))(blstm_layer)
lstm_layer3 = Bidirectional(LSTM(units = 15,return_sequences=True))(lstm_layer2)

attention =Attention()([lstm_layer3,lstm_layer3])
merged = Concatenate()([lstm_layer3, attention])
flatten = Flatten()(merged)
output_layer = Dense(1)(flatten)

model = Model(inputs=input_layer,outputs = output_layer)
from keras.layers import Dropout

dropout1 = Dropout(0.2)(lstm_layer2)
dropout2 = Dropout(0.2)(lstm_layer3)

model.compile(optimizer='rmsprop',loss='mean_squared_error')
early_stopping = EarlyStopping(monitor='val_loss',patience=3,restore_best_weights=True)
model.fit(X_train_scaled, y_train_scaled,epochs=12,validation_data=(X_test_scaled,y_test_scaled),callbacks=[early_stopping])
loss = model.evaluate(X_test_scaled,y_test_scaled)
print(f"Test loss:{loss}")

# predictions = model.predict(X_test)
# # predictions = sc.inverse_transform(predictions)
y_pred_scaled = model.predict(X_test_scaled)
predictions = sc_y.inverse_transform(y_pred_scaled)
y_test = sc_y.inverse_transform(y_test_scaled)

from sklearn.metrics import mean_absolute_percentage_error
mape = mean_absolute_percentage_error(y_test,predictions)*100
print(mape)